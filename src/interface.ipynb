{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59592871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "mycwd = os.getcwd()\n",
    "\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:26:13.349587Z",
     "start_time": "2024-06-10T10:26:01.267922Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "Running on public URL: https://df9dc6aef016e3142d.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://df9dc6aef016e3142d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Work\\Instruments\\Anaconda\\envs\\ds_project\\lib\\site-packages\\uvicorn\\protocols\\http\\h11_impl.py\", line 407, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "  File \"e:\\Work\\Instruments\\Anaconda\\envs\\ds_project\\lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 78, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "  File \"e:\\Work\\Instruments\\Anaconda\\envs\\ds_project\\lib\\site-packages\\fastapi\\applications.py\", line 292, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"e:\\Work\\Instruments\\Anaconda\\envs\\ds_project\\lib\\site-packages\\starlette\\applications.py\", line 122, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"e:\\Work\\Instruments\\Anaconda\\envs\\ds_project\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 184, in __call__\n",
      "    raise exc\n",
      "  File \"e:\\Work\\Instruments\\Anaconda\\envs\\ds_project\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 162, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"e:\\Work\\Instruments\\Anaconda\\envs\\ds_project\\lib\\site-packages\\gradio\\route_utils.py\", line 714, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"e:\\Work\\Instruments\\Anaconda\\envs\\ds_project\\lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 79, in __call__\n",
      "    raise exc\n",
      "  File \"e:\\Work\\Instruments\\Anaconda\\envs\\ds_project\\lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 68, in __call__\n",
      "    await self.app(scope, receive, sender)\n",
      "  File \"e:\\Work\\Instruments\\Anaconda\\envs\\ds_project\\lib\\site-packages\\fastapi\\middleware\\asyncexitstack.py\", line 20, in __call__\n",
      "    raise e\n",
      "  File \"e:\\Work\\Instruments\\Anaconda\\envs\\ds_project\\lib\\site-packages\\fastapi\\middleware\\asyncexitstack.py\", line 17, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"e:\\Work\\Instruments\\Anaconda\\envs\\ds_project\\lib\\site-packages\\starlette\\routing.py\", line 718, in __call__\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"e:\\Work\\Instruments\\Anaconda\\envs\\ds_project\\lib\\site-packages\\starlette\\routing.py\", line 276, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"e:\\Work\\Instruments\\Anaconda\\envs\\ds_project\\lib\\site-packages\\starlette\\routing.py\", line 69, in app\n",
      "    await response(scope, receive, send)\n",
      "  File \"e:\\Work\\Instruments\\Anaconda\\envs\\ds_project\\lib\\site-packages\\starlette\\responses.py\", line 358, in __call__\n",
      "    await send(\n",
      "  File \"e:\\Work\\Instruments\\Anaconda\\envs\\ds_project\\lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 65, in sender\n",
      "    await send(message)\n",
      "  File \"e:\\Work\\Instruments\\Anaconda\\envs\\ds_project\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 159, in _send\n",
      "    await send(message)\n",
      "  File \"e:\\Work\\Instruments\\Anaconda\\envs\\ds_project\\lib\\site-packages\\uvicorn\\protocols\\http\\h11_impl.py\", line 520, in send\n",
      "    output = self.conn.send(event)\n",
      "  File \"e:\\Work\\Instruments\\Anaconda\\envs\\ds_project\\lib\\site-packages\\h11\\_connection.py\", line 512, in send\n",
      "    data_list = self.send_with_data_passthrough(event)\n",
      "  File \"e:\\Work\\Instruments\\Anaconda\\envs\\ds_project\\lib\\site-packages\\h11\\_connection.py\", line 545, in send_with_data_passthrough\n",
      "    writer(event, data_list.append)\n",
      "  File \"e:\\Work\\Instruments\\Anaconda\\envs\\ds_project\\lib\\site-packages\\h11\\_writers.py\", line 67, in __call__\n",
      "    self.send_eom(event.headers, write)\n",
      "  File \"e:\\Work\\Instruments\\Anaconda\\envs\\ds_project\\lib\\site-packages\\h11\\_writers.py\", line 96, in send_eom\n",
      "    raise LocalProtocolError(\"Too little data for declared Content-Length\")\n",
      "h11._util.LocalProtocolError: Too little data for declared Content-Length\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image shape: (648, 836, 3)\n",
      "Processed image for ResNet model: tf.Tensor(\n",
      "[[[151.061     138.22101   131.32     ]\n",
      "  [151.061     138.22101   131.32     ]\n",
      "  [151.061     138.22101   131.32     ]\n",
      "  ...\n",
      "  [151.061     138.22101   131.32     ]\n",
      "  [151.061     138.22101   131.32     ]\n",
      "  [151.061     138.22101   131.32     ]]\n",
      "\n",
      " [[151.061     138.22101   131.32     ]\n",
      "  [151.061     138.22101   131.32     ]\n",
      "  [151.061     138.22101   131.32     ]\n",
      "  ...\n",
      "  [151.061     138.22101   131.32     ]\n",
      "  [151.061     138.22101   131.32     ]\n",
      "  [151.061     138.22101   131.32     ]]\n",
      "\n",
      " [[151.061     138.22101   131.32     ]\n",
      "  [151.061     138.22101   131.32     ]\n",
      "  [151.061     138.22101   131.32     ]\n",
      "  ...\n",
      "  [151.061     138.22101   131.32     ]\n",
      "  [151.061     138.22101   131.32     ]\n",
      "  [151.061     138.22101   131.32     ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ -1.095253   13.260063   37.585625 ]\n",
      "  [ 11.8656845  29.924126   57.421562 ]\n",
      "  [ 19.576622   48.31475    79.945    ]\n",
      "  ...\n",
      "  [-23.548378  -35.677437  -43.289375 ]\n",
      "  [151.061     138.22101   131.32     ]\n",
      "  [151.061     138.22101   131.32     ]]\n",
      "\n",
      " [[ 89.45162    96.37725   107.91375  ]\n",
      "  [ 42.271935   36.99444    43.468437 ]\n",
      "  [ 73.436      81.47881    95.43719  ]\n",
      "  ...\n",
      "  [ 50.170372   37.330376   30.429375 ]\n",
      "  [ 52.35006    39.510063   32.609062 ]\n",
      "  [151.061     138.22101   131.32     ]]\n",
      "\n",
      " [[131.10788   122.54131   120.20281  ]\n",
      "  [127.15475   118.57256   116.78875  ]\n",
      "  [123.53756   111.69756   108.23406  ]\n",
      "  ...\n",
      "  [126.88131   114.04131   107.14031  ]\n",
      "  [123.990685  111.15069   104.24969  ]\n",
      "  [126.186     113.346     106.445    ]]], shape=(32, 32, 3), dtype=float32)\n",
      "Resized image shape: (32, 32, 3)\n",
      "Input to the model: tf.Tensor(\n",
      "[[[[151.061     138.22101   131.32     ]\n",
      "   [151.061     138.22101   131.32     ]\n",
      "   [151.061     138.22101   131.32     ]\n",
      "   ...\n",
      "   [151.061     138.22101   131.32     ]\n",
      "   [151.061     138.22101   131.32     ]\n",
      "   [151.061     138.22101   131.32     ]]\n",
      "\n",
      "  [[151.061     138.22101   131.32     ]\n",
      "   [151.061     138.22101   131.32     ]\n",
      "   [151.061     138.22101   131.32     ]\n",
      "   ...\n",
      "   [151.061     138.22101   131.32     ]\n",
      "   [151.061     138.22101   131.32     ]\n",
      "   [151.061     138.22101   131.32     ]]\n",
      "\n",
      "  [[151.061     138.22101   131.32     ]\n",
      "   [151.061     138.22101   131.32     ]\n",
      "   [151.061     138.22101   131.32     ]\n",
      "   ...\n",
      "   [151.061     138.22101   131.32     ]\n",
      "   [151.061     138.22101   131.32     ]\n",
      "   [151.061     138.22101   131.32     ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ -1.095253   13.260063   37.585625 ]\n",
      "   [ 11.8656845  29.924126   57.421562 ]\n",
      "   [ 19.576622   48.31475    79.945    ]\n",
      "   ...\n",
      "   [-23.548378  -35.677437  -43.289375 ]\n",
      "   [151.061     138.22101   131.32     ]\n",
      "   [151.061     138.22101   131.32     ]]\n",
      "\n",
      "  [[ 89.45162    96.37725   107.91375  ]\n",
      "   [ 42.271935   36.99444    43.468437 ]\n",
      "   [ 73.436      81.47881    95.43719  ]\n",
      "   ...\n",
      "   [ 50.170372   37.330376   30.429375 ]\n",
      "   [ 52.35006    39.510063   32.609062 ]\n",
      "   [151.061     138.22101   131.32     ]]\n",
      "\n",
      "  [[131.10788   122.54131   120.20281  ]\n",
      "   [127.15475   118.57256   116.78875  ]\n",
      "   [123.53756   111.69756   108.23406  ]\n",
      "   ...\n",
      "   [126.88131   114.04131   107.14031  ]\n",
      "   [123.990685  111.15069   104.24969  ]\n",
      "   [126.186     113.346     106.445    ]]]], shape=(1, 32, 32, 3), dtype=float32)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Predictions: [6.0088113e-03 4.4015472e-04 2.5559846e-05 4.9502683e-01 3.9202659e-04\n",
      " 4.9483281e-01 5.6489365e-04 8.8563090e-04 5.4832129e-04 1.2748617e-03]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import gradio as gr\n",
    "import requests\n",
    "from notebooks.load_dataset.dataset import classes\n",
    "import numpy as np\n",
    "\n",
    "nm_model = tf.keras.models.load_model(\"../models/mn_model.keras\")\n",
    "\n",
    "resnet_model = tf.keras.models.load_model(\"../models/resnet_best.h5\")\n",
    "\n",
    "cifar10_labels = classes\n",
    "\n",
    "\n",
    "def classify_image(inp, model_choice):\n",
    "    try:\n",
    "        print(\"Original image shape:\", inp.shape)\n",
    "\n",
    "        if model_choice == \"MobileNetBased Model\":\n",
    "            inp = tf.image.resize(inp, (32, 32))\n",
    "\n",
    "            print(\"Processed image for MobileNet model:\", inp)\n",
    "            model = nm_model\n",
    "            labels = cifar10_labels\n",
    "        elif model_choice == \"ResNetBased Model\":\n",
    "            inp = tf.image.resize(inp, (32, 32))\n",
    "            inp = tf.keras.applications.resnet.preprocess_input(inp)\n",
    "            print(\"Processed image for ResNet model:\", inp)\n",
    "            model = resnet_model\n",
    "            labels = cifar10_labels\n",
    "\n",
    "        print(\"Resized image shape:\", inp.shape)\n",
    "\n",
    "        inp = tf.expand_dims(inp, axis=0)\n",
    "        print(\"Input to the model:\", inp)\n",
    "\n",
    "        prediction = model.predict(inp).flatten()\n",
    "        print(\"Predictions:\", prediction)\n",
    "\n",
    "        if model_choice == \"MobileNetV2\":\n",
    "            top_indices = prediction.argsort()[-10:][::-1]\n",
    "            confidences = {labels[i]: float(prediction[i]) for i in top_indices}\n",
    "        else:\n",
    "            confidences = {labels[i]: float(prediction[i]) for i in range(len(labels))}\n",
    "\n",
    "        return confidences\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=classify_image,\n",
    "    inputs=[gr.Image(type=\"numpy\", image_mode=\"RGB\", label=\"Input Image\"), gr.Dropdown([\"ResNetBased Model\", \"MobileNetBased Model\"], value=\"ResNetBased Model\", label=\"Model Choice\")],\n",
    "    outputs=gr.Label(num_top_classes=3, label=\"Predictions\"),\n",
    ")\n",
    "\n",
    "interface.launch(debug=False, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3216d0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Goit\\\\projects\\\\Data_Science_core\\\\final_data_project\\\\ds_project\\\\src'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
